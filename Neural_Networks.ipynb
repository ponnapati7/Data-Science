{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.17.0\n",
        "!pip install keras>=3.2.0\n",
        "!pip install --upgrade scikeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPro-RN-hHVd",
        "outputId": "3531d6ae-a4bc-4841-a97a-1a1df45880dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.17.0 in /usr/local/lib/python3.11/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.0) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.0) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.0) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.0) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.0) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.0) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.0) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.0) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.0) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.0) (3.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.0) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.17.0) (1.24.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.17.0) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow==2.17.0) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow==2.17.0) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow==2.17.0) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow==2.17.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow==2.17.0) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow==2.17.0) (0.1.2)\n",
            "Requirement already satisfied: scikeras in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from scikeras) (3.8.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from scikeras) (1.6.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (1.24.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (24.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras>=3.2.0->scikeras) (4.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show tensorflow keras scikeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxNEU_JLhlnz",
        "outputId": "27fcc65c-b6d0-4bc5-810f-396b8d4212e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.17.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
            "Required-by: dopamine_rl, tf_keras\n",
            "---\n",
            "Name: keras\n",
            "Version: 3.8.0\n",
            "Summary: Multi-backend Keras\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: Keras team <keras-users@googlegroups.com>\n",
            "License: Apache License 2.0\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: absl-py, h5py, ml-dtypes, namex, numpy, optree, packaging, rich\n",
            "Required-by: keras-tuner, scikeras, tensorflow\n",
            "---\n",
            "Name: scikeras\n",
            "Version: 0.13.0\n",
            "Summary: Scikit-Learn API wrapper for Keras.\n",
            "Home-page: https://github.com/adriangb/scikeras\n",
            "Author: Adrian Garcia Badaracco\n",
            "Author-email: 1755071+adriangb@users.noreply.github.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: keras, scikit-learn\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scikeras.wrappers import KerasClassifier"
      ],
      "metadata": {
        "id": "mf0VwEd-EqHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Alphabets_data.csv')"
      ],
      "metadata": {
        "id": "eYTja_38yujD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Exploration and Preprocessing**\n"
      ],
      "metadata": {
        "id": "DN8o1teh8vVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore the dataset\n",
        "print(\"Dataset shape:\", df.shape)  # Number of samples and features\n",
        "print(\"\\nData types:\\n\", df.dtypes)\n",
        "print(\"\\nFirst few rows:\\n\", df.head())\n",
        "print(\"\\nSummary Statistics:\\n\", df.describe())\n",
        "print(\"\\nMissing values:\\n\", df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGe8dloqywUC",
        "outputId": "a74f8881-9716-4b78-ef0b-dd6b01d8188a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (20000, 17)\n",
            "\n",
            "Data types:\n",
            " letter    object\n",
            "xbox       int64\n",
            "ybox       int64\n",
            "width      int64\n",
            "height     int64\n",
            "onpix      int64\n",
            "xbar       int64\n",
            "ybar       int64\n",
            "x2bar      int64\n",
            "y2bar      int64\n",
            "xybar      int64\n",
            "x2ybar     int64\n",
            "xy2bar     int64\n",
            "xedge      int64\n",
            "xedgey     int64\n",
            "yedge      int64\n",
            "yedgex     int64\n",
            "dtype: object\n",
            "\n",
            "First few rows:\n",
            "   letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
            "0      T     2     8      3       5      1     8    13      0      6      6   \n",
            "1      I     5    12      3       7      2    10     5      5      4     13   \n",
            "2      D     4    11      6       8      6    10     6      2      6     10   \n",
            "3      N     7    11      6       6      3     5     9      4      6      4   \n",
            "4      G     2     1      3       1      1     8     6      6      6      6   \n",
            "\n",
            "   x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
            "0      10       8      0       8      0       8  \n",
            "1       3       9      2       8      4      10  \n",
            "2       3       7      3       7      3       9  \n",
            "3       4      10      6      10      2       8  \n",
            "4       5       9      1       7      5      10  \n",
            "\n",
            "Summary Statistics:\n",
            "                xbox          ybox         width       height         onpix  \\\n",
            "count  20000.000000  20000.000000  20000.000000  20000.00000  20000.000000   \n",
            "mean       4.023550      7.035500      5.121850      5.37245      3.505850   \n",
            "std        1.913212      3.304555      2.014573      2.26139      2.190458   \n",
            "min        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
            "25%        3.000000      5.000000      4.000000      4.00000      2.000000   \n",
            "50%        4.000000      7.000000      5.000000      6.00000      3.000000   \n",
            "75%        5.000000      9.000000      6.000000      7.00000      5.000000   \n",
            "max       15.000000     15.000000     15.000000     15.00000     15.000000   \n",
            "\n",
            "               xbar          ybar         x2bar         y2bar         xybar  \\\n",
            "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
            "mean       6.897600      7.500450      4.628600      5.178650      8.282050   \n",
            "std        2.026035      2.325354      2.699968      2.380823      2.488475   \n",
            "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
            "25%        6.000000      6.000000      3.000000      4.000000      7.000000   \n",
            "50%        7.000000      7.000000      4.000000      5.000000      8.000000   \n",
            "75%        8.000000      9.000000      6.000000      7.000000     10.000000   \n",
            "max       15.000000     15.000000     15.000000     15.000000     15.000000   \n",
            "\n",
            "            x2ybar        xy2bar         xedge        xedgey         yedge  \\\n",
            "count  20000.00000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
            "mean       6.45400      7.929000      3.046100      8.338850      3.691750   \n",
            "std        2.63107      2.080619      2.332541      1.546722      2.567073   \n",
            "min        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
            "25%        5.00000      7.000000      1.000000      8.000000      2.000000   \n",
            "50%        6.00000      8.000000      3.000000      8.000000      3.000000   \n",
            "75%        8.00000      9.000000      4.000000      9.000000      5.000000   \n",
            "max       15.00000     15.000000     15.000000     15.000000     15.000000   \n",
            "\n",
            "            yedgex  \n",
            "count  20000.00000  \n",
            "mean       7.80120  \n",
            "std        1.61747  \n",
            "min        0.00000  \n",
            "25%        7.00000  \n",
            "50%        8.00000  \n",
            "75%        9.00000  \n",
            "max       15.00000  \n",
            "\n",
            "Missing values:\n",
            " letter    0\n",
            "xbox      0\n",
            "ybox      0\n",
            "width     0\n",
            "height    0\n",
            "onpix     0\n",
            "xbar      0\n",
            "ybar      0\n",
            "x2bar     0\n",
            "y2bar     0\n",
            "xybar     0\n",
            "x2ybar    0\n",
            "xy2bar    0\n",
            "xedge     0\n",
            "xedgey    0\n",
            "yedge     0\n",
            "yedgex    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify classes\n",
        "if 'Class' in df.columns:  # Assuming the class column is named 'Class'\n",
        "  print(f\"\\nClasses: {df['Class'].unique()}\")\n",
        "  print(\"\\nClass Counts:\\n\", df['Class'].value_counts())\n",
        "else:\n",
        "  print(\"\\nWarning: 'Class' column not found in the dataset.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kmYG6YFy5WB",
        "outputId": "2f905287-a1d8-4ec5-ccf9-caee2b5073f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Warning: 'Class' column not found in the dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Handling missing values (using SimpleImputer)\n",
        "\n",
        "# Assuming numerical features need imputation, replace with the mean\n",
        "numerical_features = df.select_dtypes(include=['number']).columns\n",
        "\n",
        "if len(numerical_features) > 0:\n",
        "  imputer = SimpleImputer(strategy='mean')  # or 'median', 'most_frequent', etc.\n",
        "  df[numerical_features] = imputer.fit_transform(df[numerical_features])\n",
        "else:\n",
        "  print(\"\\nWarning: No numerical features found for imputation.\")"
      ],
      "metadata": {
        "id": "OCFUhE08zVqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Data Normalization (using MinMaxScaler)\n",
        "scaler = MinMaxScaler()\n",
        "numerical_features = df.select_dtypes(include=['number']).columns\n",
        "\n",
        "if len(numerical_features) > 0:\n",
        "  df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
        "else:\n",
        "  print(\"\\nWarning: No numerical features found for normalization.\")\n",
        "\n",
        "\n",
        "print(\"\\nDataset after preprocessing:\\n\", df.head())\n",
        "print(\"\\nMissing values after preprocessing:\\n\", df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8g3Jjht9zsIC",
        "outputId": "8f7e2dc4-824d-465b-cc2e-dd9ab644d6fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset after preprocessing:\n",
            "   letter      xbox      ybox  width    height     onpix      xbar      ybar  \\\n",
            "0      T  0.133333  0.533333    0.2  0.333333  0.066667  0.533333  0.866667   \n",
            "1      I  0.333333  0.800000    0.2  0.466667  0.133333  0.666667  0.333333   \n",
            "2      D  0.266667  0.733333    0.4  0.533333  0.400000  0.666667  0.400000   \n",
            "3      N  0.466667  0.733333    0.4  0.400000  0.200000  0.333333  0.600000   \n",
            "4      G  0.133333  0.066667    0.2  0.066667  0.066667  0.533333  0.400000   \n",
            "\n",
            "      x2bar     y2bar     xybar    x2ybar    xy2bar     xedge    xedgey  \\\n",
            "0  0.000000  0.400000  0.400000  0.666667  0.533333  0.000000  0.533333   \n",
            "1  0.333333  0.266667  0.866667  0.200000  0.600000  0.133333  0.533333   \n",
            "2  0.133333  0.400000  0.666667  0.200000  0.466667  0.200000  0.466667   \n",
            "3  0.266667  0.400000  0.266667  0.266667  0.666667  0.400000  0.666667   \n",
            "4  0.400000  0.400000  0.400000  0.333333  0.600000  0.066667  0.466667   \n",
            "\n",
            "      yedge    yedgex  \n",
            "0  0.000000  0.533333  \n",
            "1  0.266667  0.666667  \n",
            "2  0.200000  0.600000  \n",
            "3  0.133333  0.533333  \n",
            "4  0.333333  0.666667  \n",
            "\n",
            "Missing values after preprocessing:\n",
            " letter    0\n",
            "xbox      0\n",
            "ybox      0\n",
            "width     0\n",
            "height    0\n",
            "onpix     0\n",
            "xbar      0\n",
            "ybar      0\n",
            "x2bar     0\n",
            "y2bar     0\n",
            "xybar     0\n",
            "x2ybar    0\n",
            "xy2bar    0\n",
            "xedge     0\n",
            "xedgey    0\n",
            "yedge     0\n",
            "yedgex    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Implementation**\n"
      ],
      "metadata": {
        "id": "6kvXtPkX8NgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "# Assuming the last column is the target variable (alphabet)\n",
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]"
      ],
      "metadata": {
        "id": "u1VsQAHc74J0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the target variable (alphabets) into numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)"
      ],
      "metadata": {
        "id": "IYhVNG3m79H-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "RnIXnTV9z5uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ANN model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))  # Input layer and first hidden layer\n",
        "model.add(Dense(32, activation='relu')) # Second hidden layer\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax')) # Output layer with softmax"
      ],
      "metadata": {
        "id": "mgve3tOM88x2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "YKxSLyg49D6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Before calling model.evaluate, ensure your data is of the correct type and structure.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert X_test to NumPy array with object dtype to handle mixed types\n",
        "X_test = np.asarray(X_test, dtype=object)\n",
        "\n",
        "# Iterate through columns of X_test and convert to numeric if possible\n",
        "for col in range(X_test.shape[1]):\n",
        "    try:\n",
        "        X_test[:, col] = X_test[:, col].astype(np.float32)\n",
        "    except ValueError:\n",
        "        # If conversion fails, it's likely a categorical feature\n",
        "        # Use Label Encoding or One-Hot Encoding here\n",
        "        from sklearn.preprocessing import LabelEncoder\n",
        "        encoder = LabelEncoder()\n",
        "        X_test[:, col] = encoder.fit_transform(X_test[:, col])\n",
        "\n",
        "# Convert to float32 after individual column conversions\n",
        "X_test = X_test.astype(np.float32)\n",
        "\n",
        "# Convert y_test to NumPy arrays with the correct dtype\n",
        "y_test = np.asarray(y_test, dtype=np.int32)    # Assuming your labels are integers\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "print(f'Test Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0AzFDhh7Vb_",
        "outputId": "232fae85-4828-4361-edb8-04d87d93366d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1089 - loss: 4.0229\n",
            "Test Loss: 4.036161422729492\n",
            "Test Accuracy: 0.10649999976158142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "predictions = model.predict(X_test)\n",
        "predicted_labels = [label_encoder.inverse_transform([i]) for i in predictions.argmax(axis=1)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AAQyVJI15TY",
        "outputId": "7e495f89-c82c-43fb-fe58-916a8680e5c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print some predictions\n",
        "for i in range(5): # Print the first 5 predictions\n",
        "    print(f\"Predicted: {predicted_labels[i][0]}, Actual: {label_encoder.inverse_transform([y_test[i]])[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OQDNGT9AnzN",
        "outputId": "0913eeee-b6c7-40f2-a0a2-130cf4787d79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: 0.6, Actual: 0.4\n",
            "Predicted: 0.6, Actual: 0.3333333333333333\n",
            "Predicted: 0.4, Actual: 0.5333333333333333\n",
            "Predicted: 0.6, Actual: 0.6666666666666666\n",
            "Predicted: 0.6, Actual: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "i0lJsoV-DJ4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The following hyperparameters can be tuned:**\n",
        "\n",
        "1) Number of hidden layers\n",
        "\n",
        "2) Number of neurons in each layer\n",
        "\n",
        "3) Activation function (e.g., ReLU, tanh, sigmoid)\n",
        "\n",
        "4) Learning rate of the optimizer\n",
        "\n",
        "5) Batch size and number of epochs"
      ],
      "metadata": {
        "id": "Ohd9IAclrWLY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use GridSearchCV or RandomizedSearchCV for hyperparameter tuning. However, for neural networks, KerasTuner (or similar) is a more suitable choice because GridSearchCV and RandomizedSearchCV don't directly support Keras models.\n",
        "\n",
        "Here's an example of hyperparameter tuning using KerasTuner:"
      ],
      "metadata": {
        "id": "H8VEoJYHrMwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4aWfzecpC85",
        "outputId": "0faa8234-dcc8-4d96-844d-42ec975ba484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.11/dist-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2024.12.14)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=hp.Int('units', min_value=32, max_value=128, step=32),\n",
        "                    activation='relu', input_dim=X_train.shape[1]))\n",
        "    model.add(Dense(units=hp.Int('units', min_value=32, max_value=128, step=32), activation='relu'))\n",
        "    model.add(Dense(units=len(np.unique(y)), activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer=hp.Choice('optimizer', ['adam', 'sgd']),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Preprocess X_train before passing it to the tuner\n",
        "X_train_processed = np.asarray(X_train, dtype=object)\n",
        "for col in range(X_train_processed.shape[1]):\n",
        "    try:\n",
        "        X_train_processed[:, col] = X_train_processed[:, col].astype(np.float32)\n",
        "    except ValueError:\n",
        "        encoder = LabelEncoder()\n",
        "        X_train_processed[:, col] = encoder.fit_transform(X_train_processed[:, col])\n",
        "\n",
        "X_train_processed = X_train_processed.astype(np.float32)\n",
        "\n",
        "\n",
        "tuner = kt.Hyperband(build_model, objective='val_accuracy', max_epochs=10, directory='my_dir', project_name='alphabet_tuning')\n",
        "\n",
        "# Perform the hyperparameter search, using the processed X_train\n",
        "tuner.search(X_train_processed, y_train, epochs=20, validation_split=0.2)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(1)[0]\n",
        "print(f\"Best hyperparameters: {best_hps.values}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDv0ID17nnJs",
        "outputId": "31f55bd6-e94f-4630-c57a-bd1feb6c8882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 8 Complete [00h 00m 07s]\n",
            "val_accuracy: 0.40812501311302185\n",
            "\n",
            "Best val_accuracy So Far: 0.43062499165534973\n",
            "Total elapsed time: 00h 07m 56s\n",
            "Best hyperparameters: {'units': 96, 'optimizer': 'adam', 'tuner/epochs': 2, 'tuner/initial_epoch': 0, 'tuner/bracket': 2, 'tuner/round': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Retrain Model with Best Hyperparameters**\n",
        "Once you’ve tuned the hyperparameters, retrain the model using the best configuration."
      ],
      "metadata": {
        "id": "6MoRprsWpin3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure X_train and y_train are of the correct type and structure\n",
        "X_train = np.asarray(X_train, dtype=object)\n",
        "\n",
        "# Iterate through columns of X_train and convert to numeric if possible\n",
        "for col in range(X_train.shape[1]):\n",
        "    try:\n",
        "        X_train[:, col] = X_train[:, col].astype(np.float32)\n",
        "    except ValueError:\n",
        "        # If conversion fails, it's likely a categorical feature\n",
        "        # Use Label Encoding or One-Hot Encoding here\n",
        "        from sklearn.preprocessing import LabelEncoder\n",
        "        encoder = LabelEncoder()\n",
        "        X_train[:, col] = encoder.fit_transform(X_train[:, col])\n",
        "\n",
        "# Convert to float32 after individual column conversions\n",
        "X_train = X_train.astype(np.float32)\n",
        "\n",
        "y_train = np.asarray(y_train, dtype=np.int32)    # Assuming your labels are integers\n",
        "model = build_model(best_hps)\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gV83WbNlph-I",
        "outputId": "3c61089b-669c-4826-d1ab-3b60542000f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3796 - loss: 2.0029 - val_accuracy: 0.4019 - val_loss: 1.7391\n",
            "Epoch 2/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4085 - loss: 1.6738 - val_accuracy: 0.4131 - val_loss: 1.5873\n",
            "Epoch 3/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4203 - loss: 1.5746 - val_accuracy: 0.4387 - val_loss: 1.4916\n",
            "Epoch 4/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4285 - loss: 1.4985 - val_accuracy: 0.4550 - val_loss: 1.4459\n",
            "Epoch 5/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4434 - loss: 1.4630 - val_accuracy: 0.4550 - val_loss: 1.4039\n",
            "Epoch 6/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4473 - loss: 1.4181 - val_accuracy: 0.4787 - val_loss: 1.3794\n",
            "Epoch 7/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4650 - loss: 1.3846 - val_accuracy: 0.4816 - val_loss: 1.3594\n",
            "Epoch 8/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4821 - loss: 1.3584 - val_accuracy: 0.4831 - val_loss: 1.3274\n",
            "Epoch 9/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4876 - loss: 1.3376 - val_accuracy: 0.4997 - val_loss: 1.2967\n",
            "Epoch 10/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4964 - loss: 1.3136 - val_accuracy: 0.5028 - val_loss: 1.2831\n",
            "Epoch 11/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5006 - loss: 1.3052 - val_accuracy: 0.5213 - val_loss: 1.2547\n",
            "Epoch 12/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5106 - loss: 1.2751 - val_accuracy: 0.5228 - val_loss: 1.2343\n",
            "Epoch 13/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5147 - loss: 1.2692 - val_accuracy: 0.5312 - val_loss: 1.2289\n",
            "Epoch 14/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5215 - loss: 1.2301 - val_accuracy: 0.5288 - val_loss: 1.2371\n",
            "Epoch 15/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5298 - loss: 1.2097 - val_accuracy: 0.5275 - val_loss: 1.2284\n",
            "Epoch 16/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5277 - loss: 1.2182 - val_accuracy: 0.5503 - val_loss: 1.1824\n",
            "Epoch 17/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5343 - loss: 1.1876 - val_accuracy: 0.5566 - val_loss: 1.1615\n",
            "Epoch 18/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5445 - loss: 1.1847 - val_accuracy: 0.5591 - val_loss: 1.1505\n",
            "Epoch 19/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5499 - loss: 1.1650 - val_accuracy: 0.5634 - val_loss: 1.1420\n",
            "Epoch 20/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5592 - loss: 1.1511 - val_accuracy: 0.5644 - val_loss: 1.1411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**\n"
      ],
      "metadata": {
        "id": "LKy2Py0yqBsl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate the Model's Performance**\n",
        "\n",
        "Evaluate the model using metrics like accuracy, precision, recall, and F1-score."
      ],
      "metadata": {
        "id": "icyBMZnCsnFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Predict the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = y_pred.argmax(axis=-1)\n",
        "\n",
        "# Evaluation metrics\n",
        "print(classification_report(y_test, y_pred_classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGS9WuC7qT9W",
        "outputId": "d91b5114-f38b-4004-e977-824c83cbbf2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.00      0.00      0.00         4\n",
            "           2       0.00      0.00      0.00         6\n",
            "           3       0.00      0.00      0.00        31\n",
            "           4       0.41      0.53      0.46        94\n",
            "           5       0.47      0.19      0.27       196\n",
            "           6       0.39      0.49      0.44       353\n",
            "           7       0.57      0.34      0.43       712\n",
            "           8       0.65      0.83      0.73      1596\n",
            "           9       0.41      0.29      0.34       485\n",
            "          10       0.41      0.51      0.46       308\n",
            "          11       0.61      0.54      0.57       175\n",
            "          12       0.00      0.00      0.00        29\n",
            "          13       0.00      0.00      0.00         9\n",
            "          14       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.56      4000\n",
            "   macro avg       0.26      0.25      0.25      4000\n",
            "weighted avg       0.54      0.56      0.53      4000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compare the Default and Tuned Model Performance**\n",
        "\n",
        "Compare the performance of the model before and after hyperparameter tuning. The accuracy, precision, recall, and F1-scores should be documented and discussed to show the effect of hyperparameter optimization."
      ],
      "metadata": {
        "id": "1yFbAUHis0pk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "\n",
        "Data Preprocessing: Ensuring proper scaling and handling of missing values improves model performance.\n",
        "Model Development: A simple ANN can provide decent results, but hyperparameter tuning plays a crucial role in improving its accuracy.\n",
        "Hyperparameter Tuning: Using tools like KerasTuner or GridSearchCV helps in finding optimal configurations to maximize model performance.\n",
        "Evaluation: Use appropriate classification metrics to evaluate the effectiveness of the model and tuning process.\n"
      ],
      "metadata": {
        "id": "syYlyAJys_Ta"
      }
    }
  ]
}